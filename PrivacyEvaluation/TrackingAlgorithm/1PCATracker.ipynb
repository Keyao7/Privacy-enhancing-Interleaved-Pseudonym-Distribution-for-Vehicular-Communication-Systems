{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qfOfL4NlS6cj"},"outputs":[],"source":["!pip install filterpy\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","from collections import defaultdict\n","import csv\n","import numpy as np\n","from scipy.spatial.distance import euclidean\n","from filterpy.kalman import KalmanFilter\n","from filterpy.kalman import ExtendedKalmanFilter\n","import math\n","from typing import Optional\n","import pandas as pd\n","import json\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hz6GlSYYS-Wc"},"outputs":[],"source":["class VehicleKalmanFilter:\n","    def __init__(self, initial_position, initial_velocity):\n","        self.kf = KalmanFilter(dim_x=4, dim_z=2)  # State: [x, y, vx, vy]\n","        self.kf.x = np.array([initial_position[0], initial_position[1],\n","                              initial_velocity[0], initial_velocity[1]])\n","        self.kf.F = np.array([[1, 0, 0, 0],\n","                              [0, 1, 0, 0],\n","                              [0, 0, 1, 0],\n","                              [0, 0, 0, 1]])\n","        self.kf.H = np.array([[1, 0, 0, 0],\n","                              [0, 1, 0, 0]])\n","        self.kf.P *= 1000.  # Initial uncertainty\n","        self.kf.R = np.eye(2) * 10  # Measurement uncertainty\n","        self.kf.Q = np.eye(4) * 0.1  # Process uncertainty\n","\n","    def predict(self, time_diff):\n","        self.kf.F = np.array([\n","            [1, 0, time_diff, 0],\n","            [0, 1, 0, time_diff],\n","            [0, 0, 1, 0],\n","            [0, 0, 0, 1]\n","        ])\n","        # Recalculate process noise Q\n","        dt = time_diff\n","        q = 0.1  # You can adjust this value based on the actual scenario\n","        self.kf.Q = np.array([\n","            [dt**4/4*q, 0, dt**3/2*q, 0],\n","            [0, dt**4/4*q, 0, dt**3/2*q],\n","            [dt**3/2*q, 0, dt**2*q, 0],\n","            [0, dt**3/2*q, 0, dt**2*q]\n","        ])\n","        self.kf.predict()\n","        return self.get_state()\n","\n","    def update(self, position, velocity=None):\n","        self.kf.update(position)\n","        if velocity is not None:\n","            self.kf.x[2:] = velocity  # If velocity is provided, directly update the velocity state\n","\n","    def get_state(self):\n","        return self.kf.x[:2], self.kf.x[2:]  # Return the current estimated position and velocity\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1967,"status":"ok","timestamp":1743337730342,"user":{"displayName":"Keyao","userId":"17515310681819484682"},"user_tz":-480},"id":"O5wkfnjH7SYf","outputId":"91718ff1-e47d-426f-8229-8589375dabba"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Thesis_data/Data/Eavesdropper_On_MixZone_Info_plus9.csv\n"]}],"source":["# Load the JSON file\n","files = os.listdir('/content/drive/My Drive/Thesis_data/Data/')\n","junction_file = \"/content/drive/My Drive/Thesis_data/Data/\" + files[0]\n","with open(junction_file, 'r') as file:\n","    junctions_data = json.load(file)\n","\n","# Function to find connection (with automatic prefix extraction for fuzzy matching)\n","def find_connection(from_lane, to_lane):\n","    # Function to extract the road prefix from the lane ID (removing the lane number suffix)\n","    def extract_road_prefix(lane_id):\n","        return lane_id.split('_')[0]\n","\n","    # Extract the road prefixes\n","    from_road_prefix = extract_road_prefix(from_lane)\n","    to_road_prefix = extract_road_prefix(to_lane)\n","\n","    # Search for a fuzzy connection\n","    for junction in junctions_data:\n","        if 'lane_connections' in junction:\n","            lane_connections = junction['lane_connections']\n","            # Search for all connections from lanes matching the from_road_prefix\n","            for lane in lane_connections:\n","                if from_road_prefix in lane:  # Matches the from_lane's road prefix\n","                    for connection in lane_connections[lane]:\n","                        if to_road_prefix in connection['to']:  # Matches the to_lane's road prefix\n","                            return True\n","\n","    return False\n","\n","# Load Eavesdropper ID\n","eavesdropper_id_file = \"/content/drive/My Drive/Thesis_data/Data/\" + files[1]\n","print(eavesdropper_id_file)\n","data = pd.read_csv(eavesdropper_id_file)\n","eavesdropper_on_mixzone_list = data['EavesdropperID'].tolist()\n","def check_mixzoneeavesdropper(id):\n","    ID = int(id)\n","    return ID in eavesdropper_on_mixzone_list\n","def get_eavesdropper_coordinates(eavesdropper_id):\n","    # Filter the dataset for the given EavesdropperID\n","    eavesdropper_data = data[data['EavesdropperID'] == int(eavesdropper_id)]\n","\n","    # Check if EavesdropperID exists in the dataset\n","    if not eavesdropper_data.empty:\n","        x, y = eavesdropper_data.iloc[0]['X'], eavesdropper_data.iloc[0]['Y']\n","        return float(x), float(y)\n","    else:\n","        return None, None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-8fggYzDu38"},"outputs":[],"source":["class Tracker:\n","  def __init__(self, tracker_mode=0):\n","\n","    self.exit_threshold = 15\n","    self.tracker_mode = tracker_mode\n","\n","    # for evaluation\n","    self.vehicle_to_pseudonyms = defaultdict(list)\n","    self.pseudonym_to_vehicleID = {}\n","    self.pseudonym_change_count = 0\n","    self.vehicle_count = 0\n","\n","    # for tracking\n","    self.current_second = None\n","    self.observed_vehicle_count = 0\n","    self.disappear_pseudonym_last_seen = defaultdict(dict)\n","    self.pseudonym_link_list = defaultdict(list)\n","    self.pseudonym_to_observed_vehicle = {}\n","    self.observed_pseudonym_changes = 0\n","    self.current_vehicles = defaultdict(dict)\n","    self.link_success_count = 0\n","    self.link_success_count_normal = 0\n","    self.link_success_count_mixzone = 0\n","\n","    self.pseudonym_change_events = []\n","\n","  def process_beacons(self, filename):\n","    previous_second_beacons = []\n","    current_second_beacons = []\n","\n","\n","    with open(filename, 'r') as file:\n","      reader = csv.DictReader(file)\n","      for row in reader:\n","        if int(row[\"Encrypted\"]) == 1:\n","          self.pseudonym_change_events.append((timestamp, vehicle_id,row[\"PositionX\"],row[\"PositionY\"]))\n","\n","        if int(row[\"Encrypted\"]) == 0:\n","          vehicle_id = row[\"VehicleID\"]\n","          pseudonym = row[\"Pseudonym\"]\n","          if vehicle_id not in self.vehicle_to_pseudonyms.keys():\n","            self.vehicle_to_pseudonyms[vehicle_id].append(pseudonym)\n","            self.vehicle_count += 1\n","          else:\n","            if pseudonym not in self.vehicle_to_pseudonyms[vehicle_id]:\n","              self.vehicle_to_pseudonyms[vehicle_id].append(pseudonym)\n","              self.pseudonym_change_count += 1\n","              timestamp = float(row['Timestamp'])\n","              self.pseudonym_change_events.append((timestamp, vehicle_id,row[\"PositionX\"],row[\"PositionY\"]))\n","\n","          self.pseudonym_to_vehicleID[pseudonym] = vehicle_id\n","\n","          timestamp = float(row['Timestamp'])\n","          second = int(timestamp)\n","\n","          if self.current_second == None:\n","            self.current_second = second\n","\n","          if self.current_second == second:\n","            current_second_beacons.append(row)\n","          else:\n","            self.process_two_seconds(previous_second_beacons, current_second_beacons)\n","            previous_second_beacons = current_second_beacons\n","            current_second_beacons = []\n","            current_second_beacons.append(row)\n","            self.current_second = second\n","\n","\n","    if previous_second_beacons and current_second_beacons:\n","      self.process_two_seconds(previous_second_beacons, current_second_beacons)\n","\n","  def process_two_seconds(self, previous_beacons, current_beacons):\n","    # process each two seconds of beacons\n","    previous_pseudonyms = set(beacon['Pseudonym'] for beacon in previous_beacons)\n","    current_pseudonyms = set(beacon['Pseudonym'] for beacon in current_beacons)\n","\n","    # find out the disappeared and new pseudonyms\n","    disappeared_pseudonyms = previous_pseudonyms - current_pseudonyms\n","    new_pseudonyms = current_pseudonyms - previous_pseudonyms\n","\n","    # find out the common pseudonyms\n","    common_pseudonyms = current_pseudonyms & previous_pseudonyms\n","\n","    new_pseudonyms_beacons = []\n","    common_pseudonyms_beacons = []\n","    connected_beacons = []\n","    connected_pseudonyms = []\n","    old_pseudonyms = []\n","    exit_pseudonyms = []\n","    delayed_pseudonyms = []\n","\n","    for pseudonym in disappeared_pseudonyms:\n","      self.handle_disappeared_pseudonym(pseudonym)\n","\n","\n","    # handle disappeared pseudonyms\n","    if self.disappear_pseudonym_last_seen:\n","      for old_pseudonym in self.disappear_pseudonym_last_seen.keys():\n","        if old_pseudonym in new_pseudonyms:\n","          new_pseudonyms.remove(old_pseudonym)\n","          common_pseudonyms.add(old_pseudonym)\n","          delayed_pseudonyms.append(old_pseudonym)\n","        else:\n","          if check_mixzoneeavesdropper(self.disappear_pseudonym_last_seen[old_pseudonym][\"eavesdropperid\"]):\n","            if self.current_second - self.disappear_pseudonym_last_seen[old_pseudonym][\"time\"] >= 120:\n","              exit_pseudonyms.append(old_pseudonym)\n","          else:\n","            if self.current_second - self.disappear_pseudonym_last_seen[old_pseudonym][\"time\"] >= self.exit_threshold:\n","               exit_pseudonyms.append(old_pseudonym)\n","\n","    for exit_pseudonym in exit_pseudonyms:\n","      self.disappear_pseudonym_last_seen.pop(exit_pseudonym)\n","\n","\n","    for beacon in current_beacons:\n","      pseudonym = beacon['Pseudonym']\n","      if pseudonym in new_pseudonyms:\n","        new_pseudonyms_beacons.append(beacon)\n","      elif pseudonym in common_pseudonyms:\n","        common_pseudonyms_beacons.append(beacon)\n","\n","    for pseudonym in disappeared_pseudonyms:\n","      if check_mixzoneeavesdropper(self.disappear_pseudonym_last_seen[pseudonym][\"eavesdropperid\"]):\n","        eavesdropperX, eavesdropperY = get_eavesdropper_coordinates(self.disappear_pseudonym_last_seen[pseudonym][\"eavesdropperid\"])\n","        eavesdropperPos = np.array([eavesdropperX, eavesdropperY])\n","        distance_diff = euclidean(eavesdropperPos, self.disappear_pseudonym_last_seen[pseudonym][\"position\"])\n","        if distance_diff <= 60:\n","          linked_flag, result, pseudonym_new = self.try_link_pseudonym_inMixZone(new_pseudonyms_beacons, pseudonym)\n","        else:\n","          linked_flag, result, pseudonym_new = self.try_link_pseudonym(new_pseudonyms_beacons, pseudonym)\n","      else:\n","        linked_flag, result, pseudonym_new = self.try_link_pseudonym(new_pseudonyms_beacons, pseudonym)\n","      if linked_flag:\n","          self.observed_pseudonym_changes += 1\n","          connected_pseudonyms.append(pseudonym_new)\n","          connected_beacons.append(result)\n","          new_pseudonyms = [item for item in new_pseudonyms if item not in connected_pseudonyms]\n","          new_pseudonyms_beacons = [item for item in new_pseudonyms_beacons if item not in connected_beacons]\n","          old_pseudonyms.append(pseudonym)\n","          linked_flag = False\n","\n","\n","    if self.disappear_pseudonym_last_seen:\n","      for old_pseudonym in self.disappear_pseudonym_last_seen.keys():\n","        if old_pseudonym not in old_pseudonyms:\n","          if check_mixzoneeavesdropper(self.disappear_pseudonym_last_seen[old_pseudonym][\"eavesdropperid\"]):\n","            eavesdropperX, eavesdropperY = get_eavesdropper_coordinates(self.disappear_pseudonym_last_seen[old_pseudonym][\"eavesdropperid\"])\n","            eavesdropperPos = np.array([eavesdropperX, eavesdropperY])\n","            distance_diff = euclidean(eavesdropperPos, self.disappear_pseudonym_last_seen[old_pseudonym][\"position\"])\n","            if distance_diff <= 60:\n","              linked_flag, result, pseudonym_new = self.try_link_pseudonym_inMixZone(new_pseudonyms_beacons, old_pseudonym)\n","            else:\n","              linked_flag, result, pseudonym_new = self.try_link_pseudonym(new_pseudonyms_beacons, old_pseudonym)\n","          else:\n","            linked_flag, result, pseudonym_new = self.try_link_pseudonym(new_pseudonyms_beacons, old_pseudonym)\n","          if linked_flag:\n","            self.observed_pseudonym_changes += 1\n","            connected_beacons.append(result)\n","            connected_pseudonyms.append(pseudonym_new)\n","            old_pseudonyms.append(old_pseudonym)\n","            new_pseudonyms = [item for item in new_pseudonyms if item not in connected_pseudonyms]\n","            new_pseudonyms_beacons = [item for item in new_pseudonyms_beacons if item not in connected_beacons]\n","            linked_flag = False\n","\n","\n","\n","    for i in range(len(connected_pseudonyms)):\n","      self.current_vehicles[connected_pseudonyms[i]].update({\"kalman_filter\":self.disappear_pseudonym_last_seen[old_pseudonyms[i]][\"kalman_filter\"]})\n","\n","    for pseudonym in delayed_pseudonyms:\n","      self.current_vehicles[pseudonym].update({\"kalman_filter\":self.disappear_pseudonym_last_seen[pseudonym][\"kalman_filter\"]})\n","\n","    # handle connected pseudonyms\n","    for i in range(len(connected_beacons)):\n","      common_pseudonyms_beacons.append(connected_beacons[i])\n","      if old_pseudonyms[i] in self.disappear_pseudonym_last_seen.keys():\n","        del self.disappear_pseudonym_last_seen[old_pseudonyms[i]]\n","      for key in self.pseudonym_link_list.keys():\n","        if old_pseudonyms[i] in self.pseudonym_link_list[key]:\n","           self.pseudonym_link_list[key].append(connected_pseudonyms[i])\n","\n","    if len(new_pseudonyms_beacons) != 0:\n","      self.add_new_vehicle(new_pseudonyms_beacons)\n","\n","    if len(common_pseudonyms_beacons) != 0:\n","      self.update_beacon(common_pseudonyms_beacons)\n","\n","  def add_new_vehicle(self, beacons):\n","    for beacon in beacons:\n","      pseudonym = beacon['Pseudonym']\n","      position = np.array([float(beacon['PositionX']), float(beacon['PositionY'])])\n","      speed = np.array([float(beacon['SpeedX']), float(beacon['SpeedY'])])\n","      eavesdropperid = beacon[\"EavesdropperId\"]\n","      laneid = beacon[\"LaneID\"]\n","      self.observed_vehicle_count += 1\n","      self.pseudonym_link_list[self.observed_vehicle_count].append(beacon[\"Pseudonym\"])\n","      kf = VehicleKalmanFilter(position, speed)\n","      self.current_vehicles[pseudonym].update({\"VehicleID\":beacon[\"VehicleID\"],\"position\":position, \"speed\":speed, \"kalman_filter\":kf,\"eavesdropperid\":eavesdropperid,\"LaneID\":laneid})\n","\n","\n","\n","  def update_beacon(self, beacons):\n","    for beacon in beacons:\n","      pseudonym = beacon['Pseudonym']\n","      position = np.array([float(beacon['PositionX']), float(beacon['PositionY'])])\n","      speed = np.array([float(beacon['SpeedX']), float(beacon['SpeedY'])])\n","      eavesdropperid = beacon[\"EavesdropperId\"]\n","      laneid = beacon[\"LaneID\"]\n","      kf = self.current_vehicles[pseudonym][\"kalman_filter\"]\n","      kf.update(position, speed)\n","      self.current_vehicles[pseudonym].update({\"VehicleID\":beacon[\"VehicleID\"],\"position\":position, \"speed\":speed, \"kalman_filter\":kf,\"eavesdropperid\":eavesdropperid,\"LaneID\":laneid})\n","\n","\n","\n","  def handle_disappeared_pseudonym(self, pseudonym):\n","    if pseudonym in self.current_vehicles:\n","      vehicle = self.current_vehicles[pseudonym]\n","      kf = vehicle[\"kalman_filter\"]\n","      self.disappear_pseudonym_last_seen[pseudonym].update({\n","          \"VehicleID\":vehicle[\"VehicleID\"],\n","          \"kalman_filter\": kf,\n","          \"position\":vehicle[\"position\"],\n","          \"speed\":vehicle[\"speed\"],\n","          \"eavesdropperid\":vehicle[\"eavesdropperid\"],\n","          \"LaneID\":vehicle[\"LaneID\"],\n","          \"time\":self.current_second})\n","\n","      if pseudonym in self.current_vehicles:\n","        self.current_vehicles.pop(pseudonym)\n","\n","  def try_link_pseudonym(self, new_beacons, old_pseudonym):\n","    best_score_pseudonym = \"\"\n","    best_score = 0\n","    best_score_beacon = None\n","\n","    kf = self.disappear_pseudonym_last_seen[old_pseudonym]['kalman_filter']\n","    time_diff = self.current_second - self.disappear_pseudonym_last_seen[old_pseudonym]['time']\n","    if time_diff == 0:\n","      predicted_position = self.disappear_pseudonym_last_seen[old_pseudonym][\"position\"]\n","      predicted_speed = self.disappear_pseudonym_last_seen[old_pseudonym][\"speed\"]\n","    else:\n","      kf.predict(time_diff)\n","      predicted_position, predicted_speed = kf.get_state()\n","\n","\n","    for beacon in new_beacons:\n","      pseudonym = beacon['Pseudonym']\n","      position = np.array([float(beacon['PositionX']), float(beacon['PositionY'])])\n","      speed = np.array([float(beacon['SpeedX']), float(beacon['SpeedY'])])\n","      distance_diff = euclidean(predicted_position, position)\n","      speed_diff = euclidean(predicted_speed, speed)\n","      score = self.calculate_score(distance_diff, speed_diff)\n","      if score > 60:\n","        if score > best_score:\n","          best_score = score\n","          best_score_pseudonym = pseudonym\n","          best_score_beacon = beacon\n","    if best_score_pseudonym != \"\":\n","      return True, best_score_beacon, best_score_pseudonym\n","    return False, None, None\n","\n","  def try_link_pseudonym_inMixZone(self, new_beacons, old_pseudonym):\n","\n","    eavesdropperX, eavesdropperY = get_eavesdropper_coordinates(self.disappear_pseudonym_last_seen[old_pseudonym][\"eavesdropperid\"])\n","    eavesdropperPos = np.array([eavesdropperX, eavesdropperY])\n","\n","    best_score_pseudonym = \"\"\n","    best_score_beacon = None\n","\n","    for beacon in new_beacons:\n","        pseudonym = beacon['Pseudonym']\n","        position = np.array([float(beacon['PositionX']), float(beacon['PositionY'])])\n","        distance_diff = euclidean(eavesdropperPos, position)\n","        if distance_diff < 300 and find_connection(self.disappear_pseudonym_last_seen[old_pseudonym][\"LaneID\"], beacon[\"LaneID\"]):\n","            best_score_pseudonym = pseudonym\n","            best_score_beacon = beacon\n","    if best_score_pseudonym != \"\":\n","      if self.disappear_pseudonym_last_seen[old_pseudonym][\"VehicleID\"] == best_score_beacon[\"VehicleID\"]:\n","        self.link_success_count += 1\n","      return True, best_score_beacon, best_score_pseudonym\n","    else:\n","      return False, None, None\n","\n","\n","  def calculate_score(self, distance, speed_diff):\n","    position_normalized_score = np.clip(1 - distance / (100), 0, 1)\n","    speed_normalized_score = np.clip(1 - speed_diff / (100), 0, 1)\n","    base_score = position_normalized_score * 70 + speed_normalized_score * 30\n","    return base_score\n","\n","\n","  def evaluate (self, filename):\n","    self.process_beacons(filename)\n","    true_vehicle_count = self.vehicle_count\n","    observed_vehicle_count = len(self.pseudonym_link_list)\n","    true_pseudonym_change_count = self.pseudonym_change_count\n","    observed_pseudonym_change_count = self.observed_pseudonym_changes\n","\n","    coverage_results, average_coverage, single_pseudonym_vehicle_count = self.calculate_coverage()\n","\n","    # return evaluation results\n","    return {\n","            \"true_vehicle_count\": true_vehicle_count,\n","            \"observed_vehicle_count\": observed_vehicle_count,\n","            \"true_pseudonym_change_count\": true_pseudonym_change_count,\n","            \"observed_pseudonym_change_count\": observed_pseudonym_change_count,\n","            \"pseudonym_change_linked_count\": self.link_success_count,\n","            \"pseudonym_change_linked_count_rate\": self.link_success_count / true_pseudonym_change_count,\n","            \"average_coverage\": average_coverage,\n","            \"single_pseudonym_vehicle_count\": single_pseudonym_vehicle_count,\n","            \"coverage_results\": coverage_results,\n","            \"link_list\":self.pseudonym_link_list,\n","            \"normal_link_success\":self.link_success_count_normal,\n","            \"mix_link_success\":self.link_success_count_mixzone\n","        }\n","\n","  def calculate_coverage(self):\n","    for observed_vehicle_id, pseudonym_list in self.pseudonym_link_list.items():\n","      for pseudonym in pseudonym_list:\n","         self.pseudonym_to_observed_vehicle[pseudonym] = observed_vehicle_id\n","\n","    coverage_results = {}\n","    total_coverage = 0.0\n","    multi_pseudonym_vehicle_count = 0\n","    single_pseudonym_vehicle_count = 0\n","    for vehicle_id, true_pseudonym_list in self.vehicle_to_pseudonyms.items():\n","      total_pseudonyms = len(true_pseudonym_list)\n","      if total_pseudonyms > 1:\n","          # Only consider vehicles with multiple kanji characters\n","        multi_pseudonym_vehicle_count += 1\n","        observed_vehicle_counts = {}\n","\n","        for pseudonym in true_pseudonym_list:\n","            observed_vehicle_id = self.pseudonym_to_observed_vehicle.get(pseudonym)\n","            if observed_vehicle_id is not None:\n","                if observed_vehicle_id in observed_vehicle_counts:\n","                    observed_vehicle_counts[observed_vehicle_id] += 1\n","                else:\n","                    observed_vehicle_counts[observed_vehicle_id] = 1\n","        if observed_vehicle_counts:\n","            main_observed_vehicle_id = max(observed_vehicle_counts, key=observed_vehicle_counts.get)\n","            correct_pseudonyms = observed_vehicle_counts[main_observed_vehicle_id]\n","            total_observed_pseudonyms_in_main_vehicle = len(self.pseudonym_link_list[main_observed_vehicle_id])\n","            incorrect_pseudonyms_in_main_vehicle = total_observed_pseudonyms_in_main_vehicle - correct_pseudonyms\n","\n","            coverage = (correct_pseudonyms / total_pseudonyms) * (correct_pseudonyms / total_observed_pseudonyms_in_main_vehicle)\n","\n","            total_coverage += coverage\n","\n","\n","            # record the coverage results\n","            coverage_results[vehicle_id] = {\n","              \"coverage\": coverage,\n","              \"correct_pseudonyms\": correct_pseudonyms,\n","              \"total_pseudonyms\": total_pseudonyms,\n","              \"incorrect_pseudonyms_in_main_vehicle\": incorrect_pseudonyms_in_main_vehicle,\n","              \"main_observed_vehicle_id\": main_observed_vehicle_id\n","            }\n","        else:\n","            coverage_results[vehicle_id] = {\n","                \"coverage\": 0.0,\n","                \"correct_pseudonyms\": 0,\n","                \"total_pseudonyms\": total_pseudonyms,\n","                \"incorrect_pseudonyms_in_main_vehicle\": 0,\n","                \"main_observed_vehicle_id\": None\n","            }\n","      else:\n","        # For vehicles with only one character, count the number but do not calculate the coverage\n","        single_pseudonym_vehicle_count += 1\n","        coverage_results[vehicle_id] = {\n","            \"coverage\": None,\n","            \"correct_pseudonyms\": None,\n","            \"total_pseudonyms\": total_pseudonyms,\n","            \"incorrect_pseudonyms_in_main_vehicle\": None,\n","            \"main_observed_vehicle_id\": None\n","        }\n","    # calculate average coverage\n","    if multi_pseudonym_vehicle_count > 0:\n","      average_coverage = total_coverage / multi_pseudonym_vehicle_count\n","    else:\n","      average_coverage = 0.0\n","\n","    return coverage_results, average_coverage, single_pseudonym_vehicle_count\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tx7RjsZmL5fa","executionInfo":{"status":"ok","timestamp":1743341897608,"user_tz":-480,"elapsed":165374,"user":{"displayName":"Keyao","userId":"17515310681819484682"}}},"outputs":[],"source":["file_name_Baseline = \"/content/drive/My Drive/Thesis_data/Data/1PCA/Baseline_1600To1700_PeriodicalPC_1PCA_40%.csv\"\n","tracker = Tracker()\n","results_Baseline = dict(tracker.evaluate(file_name_Baseline))\n","with open('/content/drive/My Drive/tmp/Baseline_40%_1PCA_result.json', 'w') as json_file:\n","    json.dump(results_Baseline, json_file, indent=4)\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}